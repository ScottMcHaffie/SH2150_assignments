{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment III – Generative modeling\n",
    "\n",
    "Welcome to assignment 3! In this notebook we will help with some parts of the code and the rest is for you to fill in. If you find any errors, or have any feedback, please contact `joelwall@kth.se` or `mats.persson@mi.physics.kth.se`.\n",
    "\n",
    "In this assignment, to get intuition for statistical generative models, we will train a flow model to generate samples from a toy distribution in two dimensions. Then, we will move on to generating images from a data set of your choice also using a flow model. There are three image data sets to choose from, namely the same as you encountered in assignment 2:\n",
    "1. `histopathology`,\n",
    "2. `galaxies`,\n",
    "3. `brain-stroke`.\n",
    "   \n",
    "To generate images we will need to define a special type of CNN called the UNet which has found great success for image tasks in a variety of different fields. If you have time and aim for a higher grade, you will in exercise 5 be asked to extend your image flow model to a diffusion model.\n",
    "\n",
    "We will begin by defining some of the code we will need throughout the exercise, then try it out on some SDEs, and then move on to the generative modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIi0Dau49M_Y"
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, List, Type, Tuple, Dict\n",
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.axes._axes import Axes\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn as nn\n",
    "from torch.func import vmap, jacrev\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define here a helper class for SDEs:\n",
    "$$ X_t = u_t(X_t)dt + \\sigma_t dW_t $$\n",
    "where $u_t(X_t)$ is the drift coefficient (or vector field) and $\\sigma_t$ is the diffusion coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhEm9MAB-wiG"
   },
   "outputs": [],
   "source": [
    "class SDE(ABC):\n",
    "    @abstractmethod\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the drift coefficient of the SDE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (batch_size,)\n",
    "            - t: time, shape (batch_size, nts,)\n",
    "        Returns:\n",
    "            - drift_coefficient: shape (batch_size,)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def diffusion_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the diffusion coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (batch_size,)\n",
    "            - t: time, shape ()\n",
    "        Returns:\n",
    "            - diffusion_coefficient: shape (batch_size,)\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euler Maruyama method\n",
    "The Euler Maruyama method is an SDE integrator that, similar to the Euler method for ODEs, is the simplest solver for SDEs:\n",
    "$$ X_{t+h} = X_t + hu_t(X_t) + \\sqrt{h}\\sigma_t \\epsilon_t,\\quad \\epsilon_t \\sim \\mathcal{N}(0,I).$$\n",
    "Hint: `torch.rand_like(x)` returns samples from a standard normal in a tensor with equal shape as `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cLCKvH9U-9jV"
   },
   "outputs": [],
   "source": [
    "class EulerMaruyamaMethod:\n",
    "    def __init__(self, sde: SDE):\n",
    "        self.sde = sde\n",
    "    \n",
    "    def step(self, xt: torch.Tensor, t: torch.Tensor, h: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Takes one simulation step\n",
    "        Args:\n",
    "            - xt: state at time t, shape (batch_size,)\n",
    "            - t: time, shape ()\n",
    "            - h: time step, shape ()\n",
    "        Returns:\n",
    "            - nxt: state at time t + dt\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate(self, x: torch.Tensor, ts: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Simulates using the discretization gives by ts\n",
    "        Args:\n",
    "            - x: initial state at time ts[0], shape (batch_size,)\n",
    "            - ts: timesteps, shape (batch_size, num_timesteps,)\n",
    "        Returns:\n",
    "            - x_final: final state at time ts[-1], shape (batch_size,)\n",
    "        \"\"\"\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:, t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h)\n",
    "        return x\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def simulate_with_trajectory(self, x: torch.Tensor, ts: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Simulates using the discretization gives by ts\n",
    "        Args:\n",
    "            - x_init: initial state at time ts[0], shape (bs, dim)\n",
    "            - ts: timesteps, shape (bs, num_timesteps, 1)\n",
    "        Returns:\n",
    "            - xs: trajectory of xts over ts, shape (batch_size, num\n",
    "            _timesteps, dim)\n",
    "        \"\"\"\n",
    "        xs = [x.clone()]\n",
    "        nts = ts.shape[1]\n",
    "        for t_idx in tqdm(range(nts - 1)):\n",
    "            t = ts[:,t_idx]\n",
    "            h = ts[:, t_idx + 1] - ts[:, t_idx]\n",
    "            x = self.step(x, t, h)\n",
    "            xs.append(x.clone())\n",
    "        return torch.stack(xs, dim=1)\n",
    "\n",
    "\n",
    "# Helper function needed later\n",
    "def record_every(num_timesteps: int, record_every: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the indices to record in the trajectory given a record_every parameter\n",
    "    \"\"\"\n",
    "    if record_every == 1:\n",
    "        return torch.arange(num_timesteps)\n",
    "    return torch.cat(\n",
    "        [\n",
    "            torch.arange(0, num_timesteps - 1, record_every),\n",
    "            torch.tensor([num_timesteps - 1]),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownian motion\n",
    "Here you are asked to implement an SDE corresponding to Brownian motion (no drift). \n",
    "\n",
    "Hint: `torch.zeros_like` and `torch.ones_like` might come in handy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQF0WBRWHjlL"
   },
   "outputs": [],
   "source": [
    "class BrownianMotion(SDE):\n",
    "    def __init__(self, sigma: float):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the drift coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs,)\n",
    "            - t: time, shape ()\n",
    "        Returns:\n",
    "            - drift: shape (bs,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def diffusion_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the diffusion coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs,)\n",
    "            - t: time, shape ()\n",
    "        Returns:\n",
    "            - diffusion: shape (bs,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZzCafdGIBy7"
   },
   "outputs": [],
   "source": [
    "def plot_trajectories_1d(x0: torch.Tensor, simulator: EulerMaruyamaMethod, timesteps: torch.Tensor, ax: Optional[Axes] = None):\n",
    "        \"\"\"\n",
    "        Graphs the trajectories of a one-dimensional SDE with given initial values (x0) and simulation timesteps (timesteps).\n",
    "        Args:\n",
    "            - x0: state at time t, shape (num_trajectories, 1)\n",
    "            - simulator: Simulator object used to simulate\n",
    "            - t: timesteps to simulate along, shape (num_timesteps,)\n",
    "            - ax: pyplot Axes object to plot on\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "        trajectories = simulator.simulate_with_trajectory(x0, timesteps) # (num_trajectories, num_timesteps, ...)\n",
    "        for trajectory_idx in range(trajectories.shape[0]):\n",
    "            trajectory = trajectories[trajectory_idx, :, 0] # (num_timesteps,)\n",
    "            ax.plot(ts[trajectory_idx].cpu(), trajectory.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "hoj2IwtuIDqt",
    "outputId": "7f7be8c9-825e-4e22-d178-d12402ae2b10"
   },
   "outputs": [],
   "source": [
    "sigma = # TODO: choose sigma\n",
    "\n",
    "brownian_motion = BrownianMotion(sigma)\n",
    "simulator = EulerMaruyamaMethod(sde=brownian_motion)\n",
    "num_trajectories = 10\n",
    "x0 = torch.zeros(num_trajectories, 1).to(device) # Initial values - let's start at zero\n",
    "ts = torch.linspace(0.0, 1.0, 500).view(1,-1,1).expand(num_trajectories,-1,1).to(device)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = plt.gca()\n",
    "ax.set_title(r'Trajectories of Brownian Motion with $\\sigma=$' + str(sigma), fontsize=14)\n",
    "ax.set_xlabel(r'Time ($t$)', fontsize=14)\n",
    "ax.set_ylabel(r'$X_t$', fontsize=14)\n",
    "plot_trajectories_1d(x0, simulator, ts, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ornstein-Uhlenbeck process\n",
    "Here you are asked to implement an SDE corresponding to the Ornstein-Uhlenbeck process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-W9N_UqxJLSf"
   },
   "outputs": [],
   "source": [
    "class OUProcess(SDE):\n",
    "    def __init__(self, theta: float, sigma: float):\n",
    "        self.theta = theta\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def drift_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the drift coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs,)\n",
    "            - t: time, shape ()\n",
    "        Returns:\n",
    "            - drift: shape (bs,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def diffusion_coefficient(self, xt: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the diffusion coefficient of the ODE.\n",
    "        Args:\n",
    "            - xt: state at time t, shape (bs,)\n",
    "            - t: time, shape ()\n",
    "        Returns:\n",
    "            - diffusion: shape (bs,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "V2lpamNMJW17",
    "outputId": "236fc32e-ec1d-4e6a-9ee5-b960bc7a8d62"
   },
   "outputs": [],
   "source": [
    "# Try comparing multiple choices side-by-side\n",
    "thetas_and_sigmas = [\n",
    "    (0.25, 0.0),\n",
    "    (0.25, 0.25),\n",
    "    (0.25, 0.5),\n",
    "]\n",
    "simulation_time = 20\n",
    "\n",
    "num_plots = len(thetas_and_sigmas)\n",
    "fig, axes = plt.subplots(1, num_plots, figsize=(7 * num_plots, 4))\n",
    "\n",
    "for idx, (theta, sigma) in enumerate(thetas_and_sigmas):\n",
    "\n",
    "    ou_process = OUProcess(theta, sigma)\n",
    "    simulator = EulerMaruyamaMethod(sde=ou_process)\n",
    "    \n",
    "    x0 = torch.linspace(-10.0,10.0,10).view(-1,1).to(device) # Initial values - let's start at zero\n",
    "    ts = torch.linspace(0.0, simulation_time, 1000).view(1,-1,1).expand(10,-1,1).to(device)\n",
    "\n",
    "    ax = axes[idx]\n",
    "    ax.set_title(f'Trajectories of OU Process with $\\\\sigma = ${sigma}, $\\\\theta = ${theta}', fontsize=14)\n",
    "    ax.set_xlabel(r'Time ($t$)', fontsize=14)\n",
    "    ax.set_ylabel(r'$X_t$', fontsize=14)\n",
    "    plot_trajectories_1d(x0, simulator, ts, ax)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise schedulers\n",
    "Let's define some helper classes for the noise schedulers $\\alpha_t$ and $\\beta_t$. In the cell below the helper classes, you are asked to implement linear schedulers. Again, `torch.ones_like` might come in handy. You can also define other schedulers according to your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddWlL9ATPnIe"
   },
   "outputs": [],
   "source": [
    "class Alpha(ABC):\n",
    "    def __init__(self):\n",
    "        # Check alpha_t(0) = 0\n",
    "        assert torch.allclose(\n",
    "            self(torch.zeros(1,1)), torch.zeros(1,1)\n",
    "        )\n",
    "        # Check alpha_1 = 1\n",
    "        assert torch.allclose(\n",
    "            self(torch.ones(1,1)), torch.ones(1,1)\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates alpha_t. Should satisfy: self(0.0) = 0.0, self(1.0) = 1.0.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - alpha_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        t = t.unsqueeze(1) # (num_samples, 1, 1)\n",
    "        dt = vmap(jacrev(self))(t) # (num_samples, 1, 1, 1, 1)\n",
    "        return dt.view(-1, 1)\n",
    "\n",
    "class Beta(ABC):\n",
    "    def __init__(self):\n",
    "        # Check beta_0 = 1\n",
    "        assert torch.allclose(\n",
    "            self(torch.zeros(1,1)), torch.ones(1,1)\n",
    "        )\n",
    "        # Check beta_1 = 0\n",
    "        assert torch.allclose(\n",
    "            self(torch.ones(1,1)), torch.zeros(1,1)\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates alpha_t. Should satisfy: self(0.0) = 1.0, self(1.0) = 0.0.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - beta_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt beta_t.\n",
    "        Args:\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - d/dt beta_t (num_samples, 1)\n",
    "        \"\"\"\n",
    "        t = t.unsqueeze(1) # (num_samples, 1, 1)\n",
    "        dt = vmap(jacrev(self))(t) # (num_samples, 1, 1, 1, 1)\n",
    "        return dt.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsHFmYK6P3qu"
   },
   "outputs": [],
   "source": [
    "class LinearAlpha(Alpha):\n",
    "    \"\"\"\n",
    "    Implements alpha_t = t\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - t: time (num_samples,)\n",
    "        Returns:\n",
    "            - alpha_t (num_samples,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples,)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "class LinearBeta(Beta):\n",
    "    \"\"\"\n",
    "    Implements beta_t = 1-t\n",
    "    \"\"\"\n",
    "    def __call__(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - t: time (num_samples,)\n",
    "        Returns:\n",
    "            - beta_t (num_samples,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def dt(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluates d/dt alpha_t.\n",
    "        Args:\n",
    "            - t: time (num_samples,)\n",
    "        Returns:\n",
    "            - d/dt alpha_t (num_samples,)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"To be implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZuz-i3hOikA"
   },
   "outputs": [],
   "source": [
    "class Sampleable(ABC):\n",
    "    \"\"\"\n",
    "    Distribution which can be sampled from\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (num_samples,)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class Density(ABC):\n",
    "    \"\"\"\n",
    "    Distribution with tractable density\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns the log density at x.\n",
    "        Args:\n",
    "            - x: shape (batch_size, dim)\n",
    "        Returns:\n",
    "            - log_density: shape (batch_size, 1)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "        \n",
    "class IsotropicGaussian(nn.Module, Sampleable):\n",
    "    \"\"\"\n",
    "    Isotropic Gaussian N(0, std^2 I) producing arbitrary-shaped tensors.\n",
    "    shape: the *per-sample* shape, e.g. (C,H,W) or (D,)\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, std: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        self.std = std\n",
    "\n",
    "        # Track device\n",
    "        self.register_buffer(\"dummy\", torch.zeros(1))\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.shape\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.std * torch.randn(\n",
    "            (num_samples, *self.shape),\n",
    "            device=self.dummy.device\n",
    "        )\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        # Quadratic term: -1/(2σ²) * ||x||²\n",
    "        quad = -(x.pow(2).sum(dim=1)) / (2 * self.std * self.std)\n",
    "        log_norm_const = -0.5 * self.dim[0] * math.log(2 * math.pi * self.std * self.std)\n",
    "\n",
    "        # Add normalization constant\n",
    "        logp = quad + log_norm_const\n",
    "        return logp.unsqueeze(1)\n",
    "\n",
    "\n",
    "class GaussianMixture(nn.Module, Sampleable, Density):\n",
    "    \"\"\"\n",
    "    Two-dimensional Gaussian mixture model, and is a Density and a Sampleable.\n",
    "    Wrapper around torch.distributions.MixtureSameFamily.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        means: torch.Tensor,  # nmodes x data_dim\n",
    "        covs: torch.Tensor,  # nmodes x data_dim x data_dim\n",
    "        weights: torch.Tensor,  # nmodes\n",
    "    ):\n",
    "        \"\"\"\n",
    "        means: shape (nmodes, 2)\n",
    "        covs: shape (nmodes, 2, 2)\n",
    "        weights: shape (nmodes, 1)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nmodes = means.shape[0]\n",
    "        self.register_buffer(\"means\", means)\n",
    "        self.register_buffer(\"covs\", covs)\n",
    "        self.register_buffer(\"weights\", weights)\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> list:\n",
    "        return [self.means.shape[1]]\n",
    "\n",
    "    @property\n",
    "    def distribution(self):\n",
    "        return D.MixtureSameFamily(\n",
    "                mixture_distribution=D.Categorical(probs=self.weights, validate_args=False),\n",
    "                component_distribution=D.MultivariateNormal(\n",
    "                    loc=self.means,\n",
    "                    covariance_matrix=self.covs,\n",
    "                    validate_args=False,\n",
    "                ),\n",
    "                validate_args=False,\n",
    "            )\n",
    "\n",
    "    def log_density(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.distribution.log_prob(x).view(-1, 1)\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        return self.distribution.sample(torch.Size((num_samples,)))\n",
    "\n",
    "    @classmethod\n",
    "    def random_2D(\n",
    "        cls, nmodes: int, std: float, scale: float = 10.0, x_offset: float = 0.0, seed = 0.0\n",
    "    ) -> \"GaussianMixture\":\n",
    "        torch.manual_seed(seed)\n",
    "        means = (torch.rand(nmodes, 2) - 0.5) * scale + x_offset * torch.Tensor([1.0, 0.0])\n",
    "        covs = torch.diag_embed(torch.ones(nmodes, 2)) * std ** 2\n",
    "        weights = torch.ones(nmodes)\n",
    "        return cls(means, covs, weights)\n",
    "\n",
    "    @classmethod\n",
    "    def symmetric_2D(\n",
    "        cls, nmodes: int, std: float, scale: float = 10.0, x_offset: float = 0.0\n",
    "    ) -> \"GaussianMixture\":\n",
    "        angles = torch.linspace(0, 2 * np.pi, nmodes + 1)[:nmodes]\n",
    "        means = torch.stack([torch.cos(angles), torch.sin(angles)], dim=1) * scale + torch.Tensor([1.0, 0.0]) * x_offset\n",
    "        covs = torch.diag_embed(torch.ones(nmodes, 2) * std ** 2)\n",
    "        weights = torch.ones(nmodes) / nmodes\n",
    "        return cls(means, covs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "puMAZr3tOuTu"
   },
   "outputs": [],
   "source": [
    "# Several plotting utility functions\n",
    "def hist2d_samples(samples, ax: Optional[Axes] = None, bins: int = 200, scale: float = 5.0, percentile: int = 99, **kwargs):\n",
    "    H, xedges, yedges = np.histogram2d(samples[:, 0], samples[:, 1], bins=bins, range=[[-scale, scale], [-scale, scale]])\n",
    "\n",
    "    # Determine color normalization based on the 99th percentile\n",
    "    cmax = np.percentile(H, percentile)\n",
    "    cmin = 0.0\n",
    "    norm = cm.colors.Normalize(vmax=cmax, vmin=cmin)\n",
    "\n",
    "    # Plot using imshow for more control\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    ax.imshow(H.T, extent=extent, origin='lower', norm=norm, **kwargs)\n",
    "\n",
    "def hist2d_sampleable(sampleable: Sampleable, num_samples: int, ax: Optional[Axes] = None, bins=200, scale: float = 5.0, percentile: int = 99, **kwargs):\n",
    "    assert sampleable.dim == 2\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    samples = sampleable.sample(num_samples).detach().cpu() # (ns, 2)\n",
    "    hist2d_samples(samples, ax, bins, scale, percentile, **kwargs)\n",
    "\n",
    "def scatter_sampleable(sampleable: Sampleable, num_samples: int, ax: Optional[Axes] = None, **kwargs):\n",
    "    assert sampleable.dim == 2\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    samples = sampleable.sample(num_samples) # (ns, 2)\n",
    "    ax.scatter(samples[:,0].cpu(), samples[:,1].cpu(), **kwargs)\n",
    "\n",
    "def imshow_density(density: Density, x_bounds: Tuple[float, float], y_bounds: Tuple[float, float], bins: int, ax: Optional[Axes] = None, x_offset: float = 0.0, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x_min, x_max = x_bounds\n",
    "    y_min, y_max = y_bounds\n",
    "    x = torch.linspace(x_min, x_max, bins).to(device) + x_offset\n",
    "    y = torch.linspace(y_min, y_max, bins).to(device)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack([X.reshape(-1), Y.reshape(-1)], dim=-1)\n",
    "    density = density.log_density(xy).reshape(bins, bins).T\n",
    "    im = ax.imshow(density.cpu(), extent=[x_min, x_max, y_min, y_max], origin='lower', **kwargs)\n",
    "\n",
    "def contour_density(density: Density, bins: int, scale: float, ax: Optional[Axes] = None, x_offset:float = 0.0, **kwargs):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = torch.linspace(-scale + x_offset, scale + x_offset, bins).to(device)\n",
    "    y = torch.linspace(-scale, scale, bins).to(device)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    xy = torch.stack([X.reshape(-1), Y.reshape(-1)], dim=-1)\n",
    "    density = density.log_density(xy).reshape(bins, bins).T\n",
    "    im = ax.contour(density.cpu(), origin='lower', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "iuqM2Q43O-Ca",
    "outputId": "41a0dda0-daeb-4700-fb65-990355321607"
   },
   "outputs": [],
   "source": [
    "p_noise = IsotropicGaussian(shape=[2], std = 1.0).to(device)\n",
    "p_data = GaussianMixture.symmetric_2D(???).to(device) # TODO: define your toy data distribution\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(24,8))\n",
    "bins = 200\n",
    "\n",
    "scale = 15\n",
    "x_bounds = [-scale,scale]\n",
    "y_bounds = [-scale,scale]\n",
    "\n",
    "axes[0].set_title('Noise distribution', fontsize=16)\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_yticks([])\n",
    "imshow_density(density=p_noise, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=axes[0], vmin=-10, alpha=0.35, cmap=plt.get_cmap('Greys'))\n",
    "\n",
    "\n",
    "axes[1].set_title(r'Toy data distribution $p_{\\text{data}}$', fontsize=16)\n",
    "axes[1].set_xticks([])\n",
    "axes[1].set_yticks([])\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=axes[1], vmin=-10, alpha=0.35, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "axes[2].set_title(r'Noise distribution and $p_{\\text{data}}$', fontsize=16)\n",
    "axes[2].set_xticks([])\n",
    "axes[2].set_yticks([])\n",
    "imshow_density(density=p_noise, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.35, cmap=plt.get_cmap('Greys'))\n",
    "imshow_density(density=p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, vmin=-10, alpha=0.35, cmap=plt.get_cmap('Blues'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reverse process\n",
    "Here we define a class called `ReverseProcess` which we can use to sample data, noise corrupted data, the conditional vector field, and the conditional score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseProcess(nn.Module, ABC):\n",
    "    def __init__(self, p_data: Sampleable, alpha: Alpha, beta: Beta):\n",
    "        super().__init__()\n",
    "        self.p_noise = IsotropicGaussian(p_data.dim, 1.0)\n",
    "        self.p_data = p_data\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def sample_data(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples the conditioning variable z ~ p_data(x)\n",
    "        Args:\n",
    "            - num_samples: the number of samples\n",
    "        Returns:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return p_data.sample(num_samples)\n",
    "\n",
    "    def sample_noise(self, z) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples Gaussian noise from N(0, I)\n",
    "        Args:\n",
    "            - z: samples from p(z), (num_samples, dim)\n",
    "        Returns:\n",
    "            - e: samples from N(0, I), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        return torch.randn_like(z)\n",
    "\n",
    "    def sample_xt(self, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the conditional distribution p_t(x|z) = N(alpha_t * z, beta_t**2 * I_d)\n",
    "        Args:\n",
    "            - z: conditioning variable (num_samples, dim)\n",
    "            - e: samples from N(0, I), (num_samples, dim)\n",
    "            - t: time (num_samples, 1)\n",
    "        Returns:\n",
    "            - x: samples from p_t(x|z), (num_samples, dim)\n",
    "        \"\"\"\n",
    "        alpha_t = self.alpha(t)\n",
    "        beta_t = self.beta(t)\n",
    "        e = self.sample_noise(z)\n",
    "\n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def conditional_vector_field(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "            \"\"\"\n",
    "            Evaluates the conditional vector field u_t(x|z)\n",
    "            Args:\n",
    "                - x: position variable (num_samples, c, h, w)\n",
    "                - z: conditioning variable (num_samples, c, h, w)\n",
    "                - t: time (num_samples, 1, 1, 1)\n",
    "            Returns:\n",
    "                - conditional_vector_field: conditional vector field (num_samples, c, h, w)\n",
    "            \"\"\"\n",
    "            alpha_t = self.alpha(t) # (num_samples, 1, 1, 1)\n",
    "            beta_t = self.beta(t) # (num_samples, 1, 1, 1)\n",
    "            dt_alpha_t = self.alpha.dt(t) # (num_samples, 1, 1, 1)\n",
    "            dt_beta_t = self.beta.dt(t) # (num_samples, 1, 1, 1)\n",
    "    \n",
    "        raise NotImplementedError(\"To be implemented!\")\n",
    "\n",
    "    def conditional_score(self, x: torch.Tensor, z: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "bTUKOJ2o50bT",
    "outputId": "121f5e33-43b2-4f5e-8f75-c56c722857d4"
   },
   "outputs": [],
   "source": [
    "num_timesteps = 5\n",
    "\n",
    "# Initialize probability path\n",
    "path = ReverseProcess(\n",
    "    p_data = p_data,\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "# Sample\n",
    "num_samples = 1000\n",
    "z = # TODO: sample data from path\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(1, num_timesteps, figsize=(6 * num_timesteps, 6))\n",
    "\n",
    "# Sample from conditional probability paths and graph\n",
    "ts = torch.linspace(0, 1, num_timesteps).to(device)\n",
    "for tidx, t in enumerate(ts):\n",
    "    tt = t.view(1,1).expand(num_samples, 1)\n",
    "    imshow_density(density=path.p_noise, x_bounds=x_bounds, y_bounds=y_bounds, ax=axes[tidx], bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Greys'))\n",
    "    imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, ax=axes[tidx], bins=200, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "    xt = path.sample_xt(z, tt)\n",
    "    axes[tidx].scatter(xt[:,0].detach().cpu(), xt[:,1].detach().cpu(), s=1, alpha=0.25, color='black')\n",
    "    axes[tidx].axis(\"off\")\n",
    "    axes[tidx].set_title(f'$t={t}$', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP\n",
    "Now we come to the network architecture. Implement an MLP architecture that given a list of hidden dimensions `hiddens` and input dimension `dim` outputs something with dimension `dim-1` where we subtract 1 since the time variable in the input is one-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDAql0KRBhQl"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    MLP-parameterization of the vector field u_t^theta(x)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int, hiddens: List[int], activation: Type[nn.Module] = nn.SiLU):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.net = # implement the architecture using hiddens (list of hidden dimensions), and apply activation() after each layer\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, dim)\n",
    "        - t: (bs, 1)\n",
    "        Returns:\n",
    "        - epsilon_t^theta(x): (bs, dim)\n",
    "        \"\"\"\n",
    "        xt = torch.cat([x,t], dim=-1) # 3 dimensional\n",
    "        return self.net(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "Define the `get_train_loss` method according to Algorithm 1. It should sample data from `self.path` and compute the loss between the model output and the conditional vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhbQRMuACIah"
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, path: ReverseProcess, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.model = model\n",
    "\n",
    "    def get_train_loss(self, batch_size: int) -> torch.Tensor:\n",
    "        z = # sample data from path\n",
    "        t = torch.rand(batch_size, *[1]*(z.ndim-1), device=device)\n",
    "        x = # sample corrupted data from path\n",
    "        \n",
    "        ut_theta = self.model(x, t)\n",
    "\n",
    "        ut_ref = # sample conditional vector field\n",
    "\n",
    "        error = torch.sum(torch.square(ut_theta - ut_ref), dim=-1) # (bs,)\n",
    "\n",
    "        return torch.mean(error)\n",
    "\n",
    "    def get_optimizer(self, lr: float):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, batch_size: int, num_epochs: int, device: torch.device, lr: float = 1e-3) -> torch.Tensor:\n",
    "        # Start\n",
    "        self.model.to(device)\n",
    "        opt = self.get_optimizer(lr)\n",
    "        self.model.train()\n",
    "\n",
    "        # Train loop\n",
    "        pbar = tqdm(enumerate(range(num_epochs)))\n",
    "        for idx, epoch in pbar:\n",
    "            opt.zero_grad()\n",
    "            loss = self.get_train_loss(batch_size)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            pbar.set_description(f'Epoch {idx}, loss: {loss.item()}')\n",
    "\n",
    "        # Finish\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N62olljzDGuo",
    "outputId": "42a6bbab-b8bd-4f3e-c2cf-df7bd9a64fe7"
   },
   "outputs": [],
   "source": [
    "# Construct learnable vector field\n",
    "mlp = MLP(dim=, hiddens=) # TODO: define the input dimension and hidden layer dimensions\n",
    "\n",
    "# Construct trainer\n",
    "trainer = Trainer(path, mlp)\n",
    "losses = trainer.train(num_epochs=1000, device=device, lr=1e-3, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to wrap our model in an SDE class to be able to simulate the flow ODE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNT1tD3WDg4D"
   },
   "outputs": [],
   "source": [
    "class LearnedODE(SDE):\n",
    "    def __init__(self, net):\n",
    "        self.net = net\n",
    "\n",
    "    def drift_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - x: (bs, dim)\n",
    "            - t: (bs, dim)\n",
    "        Returns:\n",
    "            - u_t: (bs, dim)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.net(x,t)\n",
    "\n",
    "    def diffusion_coefficient(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - x: (bs, dim)\n",
    "            - t: (bs, dim)\n",
    "        Returns:\n",
    "            - u_t: (bs, dim)\n",
    "        \"\"\"\n",
    "        return torch.zeros_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "ZUgRfvYDFmkS",
    "outputId": "ad93202c-4f55-4f26-e4b0-b87064856ece"
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# Change these values #\n",
    "#######################\n",
    "num_samples = 1000\n",
    "num_timesteps = 1000\n",
    "num_marginals = 4\n",
    "\n",
    "\n",
    "##############\n",
    "# Setup Plot #\n",
    "##############\n",
    "scale = 15\n",
    "x_bounds = [-scale,scale]\n",
    "y_bounds = [-scale,scale]\n",
    "legend_size = 20\n",
    "markerscale = 1.8\n",
    "\n",
    "# Setup figure\n",
    "fig, axes = plt.subplots(1,3, figsize=(36, 12))\n",
    "\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"Samples from Learned SDE\", fontsize=20)\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Plot source and target\n",
    "imshow_density(density=path.p_noise, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Greys'))\n",
    "imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "# Construct integrator and plot trajectories\n",
    "ode = LearnedODE(mlp)\n",
    "simulator = EulerMaruyamaSimulator(ode)\n",
    "x0 = path.p_noise.sample(num_samples) # (num_samples, 2)\n",
    "ts = torch.linspace(0.0, 1.0, num_timesteps).view(1,-1,1).expand(num_samples,-1,1).to(device) # (num_samples, nts, 1)\n",
    "\n",
    "xts = simulator.simulate_with_trajectory(x0, ts) # (bs, nts, dim)\n",
    "\n",
    "# Extract every n-th integration step to plot\n",
    "every_n = record_every(num_timesteps=num_timesteps, record_every=num_timesteps // num_marginals)\n",
    "xts_every_n = xts[:,every_n,:] # (bs, nts // n, dim)\n",
    "ts_every_n = ts[0,every_n] # (nts // n,)\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].item()\n",
    "    ax.scatter(xts_every_n[:,plot_idx,0].detach().cpu(), xts_every_n[:,plot_idx,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt:.2f}')\n",
    "\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "\n",
    "ax = axes[2]\n",
    "ax.set_title(\"Trajectories of Learned SDE\", fontsize=20)\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Plot source and target\n",
    "imshow_density(density=path.p_noise, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Greys'))\n",
    "imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "n_traj_to_plot = num_samples // 5 if num_samples > 100 else num_samples\n",
    "for traj_idx in range(n_traj_to_plot):\n",
    "    ax.plot(xts[traj_idx,:,0].detach().cpu(), xts[traj_idx,:,1].detach().cpu(), alpha=0.5, color='black')\n",
    "\n",
    "\n",
    "\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Ground-Truth Path\", fontsize=20)\n",
    "ax.set_xlim(*x_bounds)\n",
    "ax.set_ylim(*y_bounds)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "for plot_idx in range(xts_every_n.shape[1]):\n",
    "    tt = ts_every_n[plot_idx].unsqueeze(0).expand(num_samples, 1)\n",
    "    zz = path.sample_data(num_samples)\n",
    "    x = path.sample_xt(zz, tt)\n",
    "    ax.scatter(x[:,0].detach().cpu(), x[:,1].detach().cpu(), marker='o', alpha=0.5, label=f't={tt[0,0].item():.2f}')\n",
    "\n",
    "# Plot source and target\n",
    "imshow_density(density=path.p_noise, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Greys'))\n",
    "imshow_density(density=path.p_data, x_bounds=x_bounds, y_bounds=y_bounds, bins=200, ax=ax, vmin=-10, alpha=0.25, cmap=plt.get_cmap('Blues'))\n",
    "\n",
    "ax.legend(prop={'size': legend_size}, loc='upper right', markerscale=markerscale)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJMvgiIS5haQ"
   },
   "source": [
    "# Image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yvp_j3cxfCwt"
   },
   "outputs": [],
   "source": [
    "class ImageSampler(nn.Module, Sampleable):\n",
    "    \"\"\"\n",
    "    Sampleable wrapper for your image dataset\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dataset_path = os.path.join('data', 'brain-stroke') # TODO: choose your image data set\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),\n",
    "            ])\n",
    "\n",
    "        self.dataset = self.load_data()\n",
    "        self.dummy = nn.Buffer(torch.zeros(1)) # Will automatically be moved when self.to(...) is called...\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.dataset.shape[1:]\n",
    "\n",
    "    def load_data(self):\n",
    "        images = []\n",
    "\n",
    "        for fname in os.listdir(self.dataset_path):\n",
    "            if fname.endswith('.png'):\n",
    "                fpath = os.path.join(self.dataset_path, fname)\n",
    "\n",
    "                # Load image\n",
    "                img = Image.open(fpath)\n",
    "\n",
    "                # Ensure RGB\n",
    "                img = img.convert('L') # TODO: 'L' if grayscale else 'RGB'\n",
    "\n",
    "                # Apply transform -> tensor [C, H, W]\n",
    "                img_tensor = self.transform(img)\n",
    "\n",
    "                images.append(img_tensor)\n",
    "\n",
    "        # Stack into [N, C, H, W]\n",
    "        data = torch.stack(images, dim=0)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def sample(self, num_samples: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - num_samples: the desired number of samples\n",
    "        Returns:\n",
    "            - samples: shape (batch_size, c, h, w)\n",
    "        \"\"\"\n",
    "        if num_samples > len(self.dataset):\n",
    "            raise ValueError(f\"num_samples exceeds dataset size: {len(self.dataset)}\")\n",
    "\n",
    "        indices = torch.randperm(len(self.dataset))[:num_samples]\n",
    "        samples = [self.dataset[i] for i in indices]\n",
    "        samples = torch.stack(samples).to(self.dummy)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "hUIYLWJZjJVX",
    "outputId": "f22dded9-3ee3-438e-89ff-cbc656b8c451"
   },
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "num_cols = 3\n",
    "num_timesteps = 5\n",
    "\n",
    "# Initialize our sampler\n",
    "p_data = ImageSampler().to(device)\n",
    "\n",
    "# Initialize probability path\n",
    "path = ReverseProcess(\n",
    "    p_data = p_data,\n",
    "    alpha = LinearAlpha(),\n",
    "    beta = LinearBeta()\n",
    ").to(device)\n",
    "\n",
    "# Sample\n",
    "num_samples = num_rows * num_cols\n",
    "z = # TODO: sample data from path\n",
    "\n",
    "# Setup plot\n",
    "fig, axes = plt.subplots(1, num_timesteps, figsize=(4 * num_cols * num_timesteps, 4 * num_rows))\n",
    "\n",
    "# Sample from conditional probability paths and graph\n",
    "ts = torch.linspace(0, 1, num_timesteps).to(device)\n",
    "for tidx, t in enumerate(ts):\n",
    "    tt = t.view(1,1,1,1).expand(num_samples, 1, 1, 1) # (num_samples, 1, 1, 1)\n",
    "    xt = # TODO: sample corrupted data from path\n",
    "    grid = make_grid(xt, nrow=num_cols, normalize=True, value_range=(-1,1))\n",
    "    axes[tidx].imshow(grid.permute(1, 2, 0).cpu(), cmap=\"gray\", interpolation='none')\n",
    "    axes[tidx].axis(\"off\")\n",
    "    axes[tidx].set_title(f'$t={t}$', fontsize=36)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "Here we define the UNet model for our image vector field. It is you job to fill in the missing details in the residual layer module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inSlk3OcjX3i"
   },
   "outputs": [],
   "source": [
    "class FourierEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Based on https://github.com/lucidrains/denoising-diffusion-pytorch/blob/main/denoising_diffusion_pytorch/karras_unet.py#L183\n",
    "    \"\"\"\n",
    "    def __init__(self, dim: int):\n",
    "        super().__init__()\n",
    "        assert dim % 2 == 0\n",
    "        self.half_dim = dim // 2\n",
    "        self.weights = nn.Parameter(torch.randn(1, self.half_dim))\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "        - embeddings: (bs, dim)\n",
    "        \"\"\"\n",
    "        t = t.view(-1, 1) # (bs, 1)\n",
    "        freqs = t * self.weights * 2 * math.pi # (bs, half_dim)\n",
    "        sin_embed = torch.sin(freqs) # (bs, half_dim)\n",
    "        cos_embed = torch.cos(freqs) # (bs, half_dim)\n",
    "        return torch.cat([sin_embed, cos_embed], dim=-1) * math.sqrt(2) # (bs, dim)\n",
    "\n",
    "class ResidualLayer(nn.Module):\n",
    "    def __init__(self, channels: int, time_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            # TODO: define the first residual block\n",
    "        )\n",
    "        \n",
    "        # Converts (bs, time_embed_dim) -> (bs, channels)\n",
    "        self.time_adapter = nn.Sequential(\n",
    "            nn.Linear(time_embed_dim, time_embed_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_embed_dim, channels)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            # TODO: define the second residual block\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        \"\"\"\n",
    "        res = x.clone()                      # (bs, c, h, w)\n",
    "\n",
    "        # Initial conv block\n",
    "        x = # TODO: apply first block to x   # (bs, c, h, w)\n",
    "\n",
    "        # Add time embedding\n",
    "        t_embed = self.time_adapter(t_embed).unsqueeze(-1).unsqueeze(-1) # (bs, c, 1, 1)\n",
    "        x = # TODO: add t_embed to x\n",
    "\n",
    "        # Second conv block\n",
    "        x = # TODO: apply second block to x  # (bs, c, h, w)\n",
    "\n",
    "        # Add back residual\n",
    "        x = # TODO: add res to x             # (bs, c, h, w)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_residual_layers: int, t_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels_in, t_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "        self.downsample = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c_in, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        \"\"\"\n",
    "        # Pass through residual blocks: (bs, c_in, h, w) -> (bs, c_in, h, w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed)\n",
    "\n",
    "        # Downsample: (bs, c_in, h, w) -> (bs, c_out, h // 2, w // 2)\n",
    "        x = self.downsample(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, channels: int, num_residual_layers: int, t_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels, t_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        \"\"\"\n",
    "        # Pass through residual blocks: (bs, c, h, w) -> (bs, c, h, w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, num_residual_layers: int, t_embed_dim: int):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.Conv2d(channels_in, channels_out, kernel_size=3, padding=1))\n",
    "        self.res_blocks = nn.ModuleList([\n",
    "            ResidualLayer(channels_out, t_embed_dim) for _ in range(num_residual_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_embed: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, c, h, w)\n",
    "        - t_embed: (bs, t_embed_dim)\n",
    "        \"\"\"\n",
    "        # Upsample: (bs, c_in, h, w) -> (bs, c_out, 2 * h, 2 * w)\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        # Pass through residual blocks: (bs, c_out, h, w) -> (bs, c_out, 2 * h, 2 * w)\n",
    "        for block in self.res_blocks:\n",
    "            x = block(x, t_embed)\n",
    "\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels: int, channels: List[int], num_residual_layers: int, t_embed_dim: int):\n",
    "        super().__init__()\n",
    "        # Initial convolution: (bs, ic, 32, 32) -> (bs, c_0, 32, 32)\n",
    "        self.init_conv = nn.Sequential(nn.Conv2d(input_channels, channels[0], kernel_size=3, padding=1), nn.BatchNorm2d(channels[0]), nn.SiLU())\n",
    "\n",
    "        # Initialize time embedder\n",
    "        self.time_embedder = FourierEncoder(t_embed_dim)\n",
    "\n",
    "        # Encoders, Bottleneck, and Decoders\n",
    "        encoders = []\n",
    "        decoders = []\n",
    "        for (curr_c, next_c) in zip(channels[:-1], channels[1:]):\n",
    "            encoders.append(Encoder(curr_c, next_c, num_residual_layers, t_embed_dim, y_embed_dim))\n",
    "            decoders.append(Decoder(next_c, curr_c, num_residual_layers, t_embed_dim, y_embed_dim))\n",
    "        self.encoders = nn.ModuleList(encoders)\n",
    "        self.decoders = nn.ModuleList(reversed(decoders))\n",
    "\n",
    "        # Final convolution\n",
    "        self.final_conv = nn.Conv2d(channels[0], input_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - x: (bs, 1, 32, 32)\n",
    "        - t: (bs, 1, 1, 1)\n",
    "        Returns:\n",
    "        - u_t^theta(x): (bs, 1, 32, 32)\n",
    "        \"\"\"\n",
    "        # Embed t\n",
    "        t_embed = self.time_embedder(t) # (bs, time_embed_dim)\n",
    "\n",
    "        # Initial convolution\n",
    "        x = self.init_conv(x) # (bs, c_0, 32, 32)\n",
    "\n",
    "        residuals = []\n",
    "\n",
    "        # Encoders\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, t_embed) # (bs, c_i, h, w) -> (bs, c_{i+1}, h // 2, w //2)\n",
    "            residuals.append(x.clone())\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x, t_embed)\n",
    "\n",
    "        # Decoders\n",
    "        for decoder in self.decoders:\n",
    "            res = residuals.pop() # (bs, c_i, h, w)\n",
    "            x = x + res\n",
    "            x = decoder(x, t_embed) # (bs, c_i, h, w) -> (bs, c_{i-1}, 2 * h, 2 * w)\n",
    "\n",
    "        # Final convolution\n",
    "        x = self.final_conv(x) # (bs, 1, 32, 32)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Train the UNet vector field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "47gfYi1HnOKk",
    "outputId": "a3c9142f-836c-4ad6-d2d4-6d25d81f8019"
   },
   "outputs": [],
   "source": [
    "# Initialize probability path\n",
    "path = ReverseProcess(\n",
    "    p_data = ImageSampler(),\n",
    "    alpha = , # TODO: define your alpha scheduler\n",
    "    beta =    # TODO: define your beta scheduler\n",
    ").to(device)\n",
    "\n",
    "# Initialize model\n",
    "unet = UNet(\n",
    "    input_channels = 1, # RGB or grayscale?\n",
    "    channels = [32, 64, 128],\n",
    "    num_residual_layers = 2,\n",
    "    t_embed_dim = 40,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(path = path, model = unet)\n",
    "\n",
    "# Train!\n",
    "trainer.train(num_epochs = 5000, device=device, lr=1e-3, batch_size=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "K99q2O89uucm",
    "outputId": "10528df9-6182-4436-c4a7-8631e12ca53e"
   },
   "outputs": [],
   "source": [
    "num_timesteps = 100\n",
    "num_samples = 9\n",
    "\n",
    "ode = LearnedODE(unet)\n",
    "simulator = EulerMaruyamaSimulator(ode)\n",
    "x0 = # TODO: sample initial noise from path.p_noise # (num_samples, 3, 32, 32)\n",
    "\n",
    "# Simulate\n",
    "ts = torch.linspace(0,1,num_timesteps).view(1, -1, 1, 1, 1).expand(num_samples, -1, 1, 1, 1).to(device)\n",
    "x1 = # TODO: use the simulator to simulate the ODE starting in x0\n",
    "\n",
    "plt.figure()\n",
    "grid = make_grid(x1, nrow=num_cols, normalize=True, value_range=(-1,1))\n",
    "\n",
    "plt.imshow(grid.squeeze().permute(1, 2, 0).cpu(), cmap=\"gray\", interpolation='none')\n",
    "plt.axis(\"off\")\n",
    "plt.title(f'$t={t}$', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
